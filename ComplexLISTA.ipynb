{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4657fdda-780b-41a6-89bc-23a7b3e896e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c4f57438-6d0e-4c21-8d0a-7a13203fd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import norm, pinv\n",
    "from scipy import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "041d5853-5e92-4af4-86b8-c01a2d33509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import relu, mse_loss\n",
    "from torch.nn import Module\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "27e2df59-12ae-49fd-9ee9-af5df29300d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_dataset(Dataset):\n",
    "    def __init__(self, N, K, Nexamples):\n",
    "        self.X = np.zeros((Nexamples, N, 1))\n",
    "        for ii in range(Nexamples):\n",
    "            self.X[ii,...] = self.generate_sparse_vector(N, K)\n",
    "        #self.X *= np.random.randn(*self.X.shape)\n",
    "        self.X = torch.from_numpy(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i, ...]\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def generate_sparse_vector(self, N, K):\n",
    "        x = np.zeros((N,1))\n",
    "        x[:K,...] = 1.\n",
    "        np.random.shuffle(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ef4b98a-639c-4614-addb-75f6fb5ac7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLISTA(Module):\n",
    "    \n",
    "    def __init__(self, M, N, maxit):\n",
    "        super(ComplexLISTA, self).__init__()\n",
    "    \n",
    "        # Real and imaginary Wg and We matricies \n",
    "        self.Wre = torch.nn.Parameter(torch.zeros([N, M]), requires_grad=True)\n",
    "        self.Wrg = torch.nn.Parameter(torch.zeros([N, N]), requires_grad=True)\n",
    "        self.Wie = torch.nn.Parameter(torch.zeros([N, M]), requires_grad=True)\n",
    "        self.Wig = torch.nn.Parameter(torch.zeros([N, N]), requires_grad=True)\n",
    "        \n",
    "        # alpha and lambda hyper-parameters to LASSO/ISTA\n",
    "        #self.alpha = torch.nn.Parameter(torch.zeros(maxit), requires_grad=True)\n",
    "        #self.lamda = torch.nn.Parameter(torch.zeros(maxit), requires_grad=True)\n",
    "        self.theta = torch.nn.Parameter(torch.ones(maxit+1), requires_grad=True)\n",
    "        \n",
    "        # Save the passed values\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.maxit = maxit\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, yr, yi):\n",
    "        \n",
    "        Wret = torch.transpose(self.Wre, 0, 1)\n",
    "        Wiet = torch.transpose(self.Wie, 0, 1)\n",
    "        Wrgt = torch.transpose(self.Wrg, 0, 1)\n",
    "        Wigt = torch.transpose(self.Wig, 0, 1)\n",
    "                \n",
    "        # Apply We branch to y to 0-th iteration\n",
    "        zr = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "        zi = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "        \n",
    "        # Apply soft-thresholding according to Eldar's paper.\n",
    "        xabs = torch.sqrt(torch.square(zr) + torch.square(zi))\n",
    "        soft = 1 - torch.divide(self.theta[0], relu(xabs - self.theta[0]) + self.theta[0]) \n",
    "        \n",
    "        xr = zr * soft\n",
    "        xi = zi * soft\n",
    "        \n",
    "        print(f\"{yr[0,0] = }, {zr[0,0] = }, {xr[0,0] = }, {self.theta[0] = }, {soft[0,0] = }, {self.Wre[0,0] = }, {self.Wrg[0,0] = }\")\n",
    "        \n",
    "        for t in range(1, self.maxit+1):\n",
    "        \n",
    "            # Apply We branch to y to t-th iteration\n",
    "            ar = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "            ai = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "            \n",
    "            # Apply Wg branch to x^(t) for t-th iteration\n",
    "            br = torch.matmul(xr, Wrgt) - torch.matmul(xi, Wigt)\n",
    "            bi = torch.matmul(xi, Wrgt) + torch.matmul(xr, Wigt)\n",
    "            \n",
    "            # Add the two branches\n",
    "            zr = ar + br\n",
    "            zi = ai + bi\n",
    "            \n",
    "            # Apply soft-thresholding\n",
    "            xabs = torch.sqrt(torch.square(zr) + torch.square(zi))\n",
    "            soft = 1 - torch.divide(self.theta[t], relu(xabs - self.theta[t]) + self.theta[t]) \n",
    "            \n",
    "            xr = zr * soft\n",
    "            xi = zi * soft\n",
    "            \n",
    "            if(torch.isnan(zr[0,0])):\n",
    "                raise Exception('Bad')            \n",
    "        return xr, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "646a789f-63f6-4e75-b598-ca9f8df702e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.complex128\n"
     ]
    }
   ],
   "source": [
    "# Create ULA and Nested Array Matricies\n",
    "M = 70\n",
    "N = 100\n",
    "sig = 0\n",
    "N1 = M // 2\n",
    "N2 = M - N1\n",
    "\n",
    "inner = np.arange(N1)\n",
    "outer = np.arange(1, N2+1)*(N1 + 1) - 1\n",
    "\n",
    "uniform = np.arange(M).reshape(-1,1)\n",
    "nested = np.concatenate([inner, outer]).reshape(-1, 1)\n",
    "\n",
    "fgrid = fft.fftfreq(N).reshape(-1, 1)\n",
    "\n",
    "complex_exp = lambda x : np.exp(1j* 2*np.pi * x )\n",
    "A_u = complex_exp(uniform @ fgrid.T)\n",
    "A_n = complex_exp(nested @ fgrid.T)\n",
    "\n",
    "A = torch.from_numpy(A_u)\n",
    "print(A.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "596150e5-6a33-4042-89c5-799485cd5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxit = 50\n",
    "M = 70\n",
    "N = 100\n",
    "model = ComplexLISTA(M, N, maxit)\n",
    "\n",
    "# for name, weights in model.named_parameters():\n",
    "#     print(name, weights)\n",
    "#print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a37dbeb5-7183-4320-ac99-6ac6abc5f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "epochs = 20\n",
    "batchSize = 10\n",
    "testFreq = 1\n",
    "trainingPoints = 100\n",
    "print(trainingPoints)\n",
    "testingPoints = 100\n",
    "sparsityLevel = 2\n",
    "\n",
    "dataset_training = sparse_dataset(N, sparsityLevel, trainingPoints)\n",
    "dataloader_training = DataLoader(dataset_training, \n",
    "                                 batch_size = batchSize, shuffle=True)\n",
    "dataset_testing = sparse_dataset(N, sparsityLevel, testingPoints)\n",
    "dataloader_testing = DataLoader(dataset_testing, \n",
    "                                 batch_size = 1, shuffle=False)\n",
    "batches = int(trainingPoints/batchSize)\n",
    "training_losslist = np.zeros(epochs * batches)\n",
    "testing_losslist = np.zeros(epochs * batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a399404-ab10-4076-b234-6a62a1c46392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Wg matrix according to Eldar\n",
    "X = dataset_training[...][...,0]\n",
    "Y = X @ A_u.T\n",
    "X = X.t().numpy()\n",
    "Y = Y.t().numpy()\n",
    "Phi = Y @ pinv(X.T.conj() @ X) @ X.T.conj() # conjugates omitted since X will be real\n",
    "PhiH = torch.from_numpy(Phi.conj().T)\n",
    "L = np.max(np.abs(np.linalg.eigvals(Phi.conj().T @ Phi)))\n",
    "\n",
    "#print(model.state_dict()['Wre'])\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'Wre' in name:\n",
    "            param.copy_(1/L * PhiH.real)\n",
    "        if 'Wie' in name:\n",
    "            param.copy_(1/L * PhiH.imag)\n",
    "#print(model.state_dict()['Wre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6efcd2d6-5443-46eb-9496-c365d6143d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yr[0,0] = tensor(2.), zr[0,0] = tensor(-0.0050, grad_fn=<SelectBackward>), xr[0,0] = tensor(-0., grad_fn=<SelectBackward>), self.theta[0] = tensor(1., grad_fn=<SelectBackward>), soft[0,0] = tensor(0., grad_fn=<SelectBackward>), self.Wre[0,0] = tensor(0.0100, grad_fn=<SelectBackward>), self.Wrg[0,0] = tensor(0., grad_fn=<SelectBackward>)\n",
      "yr[0,0] = tensor(2.), zr[0,0] = tensor(nan, grad_fn=<SelectBackward>), xr[0,0] = tensor(nan, grad_fn=<SelectBackward>), self.theta[0] = tensor(nan, grad_fn=<SelectBackward>), soft[0,0] = tensor(nan, grad_fn=<SelectBackward>), self.Wre[0,0] = tensor(nan, grad_fn=<SelectBackward>), self.Wrg[0,0] = tensor(nan, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Bad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70566/1353012055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Send through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mxpredr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpredi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpredr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpredi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/torch-v1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_70566/955481043.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, yr, yi)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Bad"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-10)\n",
    "obj = torch.nn.MSELoss()\n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(dataloader_training):\n",
    "\n",
    "        idx = e * batches + i\n",
    "\n",
    "        x = data.numpy().reshape(batchSize, N)\n",
    "        y = torch.from_numpy(x @ A_u.T)\n",
    "        \n",
    "        # Split data to real and complex\n",
    "        xr = data.reshape(batchSize, N).to(torch.float32)\n",
    "        xi = torch.zeros(batchSize, N).to(torch.float32)\n",
    "        \n",
    "        yr = y.real.to(torch.float32)\n",
    "        yi = y.imag.to(torch.float32)\n",
    "        \n",
    "        # Send through model\n",
    "        xpredr, xpredi = model(yr, yi)\n",
    "        \n",
    "        loss = obj(xpredr, xr) + obj(xpredi, xi)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            training_losslist[idx] = loss\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        #print(\"Epoch: {}\\t Batch: {}\\t Training Loss: {}\\t\".format(e, i, training_losslist[idx]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17f3d02c-87d5-48db-93d9-b9f700d81b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019999999552965164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f983957acd0>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(training_losslist[0])\n",
    "plt.plot(training_losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629261e3-81f8-4ba7-a3b2-1cbecfb99557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd5f85-e7da-4294-b9e8-21dbc35fd6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf067838-97c3-44d5-976e-7ab7bf006761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-v1.9.0]",
   "language": "python",
   "name": "conda-env-torch-v1.9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
